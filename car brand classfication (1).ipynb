{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rinki\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rinki\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rinki\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rinki\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rinki\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rinki\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# import the libraries as shown below\n",
    "#transfer learning techinique where we can reuse the weights \n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input # resenet50 is a neural network \n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('datasets.zip', 'r') as zf:\n",
    "    zf.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]# any size can be given depends of type of images \n",
    "\n",
    "train_path = 'Datasets/train'\n",
    "valid_path = 'Datasets/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rinki\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rinki\\anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "# Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG\n",
    "# Here we will be using imagenet weights\n",
    "\n",
    "resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)# y 3? because it is of 3 channels to make it RGV channel # we need three categories so we need not include first and last so it is false  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalizationV1) (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in resnet.layers: #tranverse through each and every layer\n",
    "    layer.trainable = False # false we dont train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for getting number of output classes\n",
    "folders = glob('Datasets/train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Datasets/train\\\\audi',\n",
       " 'Datasets/train\\\\lamborghini',\n",
       " 'Datasets/train\\\\mercedes']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(resnet.output)#flattening the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(len(folders), activation='softmax')(x) #dense layer with 3 nodes \n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=resnet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalizationV1) (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            301059      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,888,771\n",
      "Trainable params: 301,059\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image Data Generator to import the images from the dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #data augumentation  can be done by imagedatagenerator \n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, # to use ImageDataGenerator we need to scale down the values \n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory('Datasets/train',\n",
    "                                                 target_size = (224, 224), # should be same the inialized in the model \n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical') #if more than 2 clses we should use catergorial and less than 3 then binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('Datasets/test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rinki\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 9.4114 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.2772 - acc: 0.4219 - val_loss: 9.4114 - val_acc: 0.3276\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8417 - acc: 0.3276\n",
      "2/2 [==============================] - 41s 21s/step - loss: 6.0049 - acc: 0.5781 - val_loss: 10.8417 - val_acc: 0.3276\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 11.1587 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.6280 - acc: 0.6875 - val_loss: 11.1587 - val_acc: 0.3276\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 41s 20s/step - loss: 5.3023 - acc: 0.6562 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.9973 - acc: 0.6562 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 39s 20s/step - loss: 4.2319 - acc: 0.7344 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.5444 - acc: 0.7031 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.8209 - acc: 0.6875 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.6098 - acc: 0.7031 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.7831 - acc: 0.6875 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.0406 - acc: 0.7344 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 11.1006 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.2814 - acc: 0.7344 - val_loss: 11.1006 - val_acc: 0.3276\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.1104 - acc: 0.7344 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.4939 - acc: 0.7188 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.9843 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 3.7777 - acc: 0.7656 - val_loss: 10.9843 - val_acc: 0.3276\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.1734 - acc: 0.7188 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 4.0295 - acc: 0.7500 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 9s 5s/step - loss: 10.9843 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 3.7243 - acc: 0.7656 - val_loss: 10.9843 - val_acc: 0.3276\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 3.7777 - acc: 0.7656 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.6356 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 3.2957 - acc: 0.7500 - val_loss: 10.6356 - val_acc: 0.3276\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 1.5577 - acc: 0.8906 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.9843 - acc: 0.3276\n",
      "2/2 [==============================] - 40s 20s/step - loss: 0.2758 - acc: 0.9688 - val_loss: 10.9843 - val_acc: 0.3276\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 41s 20s/step - loss: 1.2674 - acc: 0.8750 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 11s 5s/step - loss: 10.9843 - acc: 0.3276\n",
      "2/2 [==============================] - 51s 26s/step - loss: 0.7763 - acc: 0.9219 - val_loss: 10.9843 - val_acc: 0.3276\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 11s 6s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 50s 25s/step - loss: 0.4798 - acc: 0.9219 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 43s 22s/step - loss: 0.9008 - acc: 0.9219 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 43s 21s/step - loss: 0.3971 - acc: 0.9688 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.6356 - acc: 0.3276\n",
      "2/2 [==============================] - 42s 21s/step - loss: 0.2520 - acc: 0.9844 - val_loss: 10.6356 - val_acc: 0.3276\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 44s 22s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 11.0424 - acc: 0.3276\n",
      "2/2 [==============================] - 42s 21s/step - loss: 0.2518 - acc: 0.9844 - val_loss: 11.0424 - val_acc: 0.3276\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 11s 5s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 46s 23s/step - loss: 0.1322 - acc: 0.9844 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 11s 5s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 48s 24s/step - loss: 0.0038 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 11s 5s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 45s 23s/step - loss: 0.3213 - acc: 0.9531 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 47s 24s/step - loss: 1.2387e-07 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 12s 6s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 43s 22s/step - loss: 0.0875 - acc: 0.9844 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 46s 23s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 46s 23s/step - loss: 1.2415e-06 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 42s 21s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 12s 6s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 42s 21s/step - loss: 0.0076 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 12s 6s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 51s 25s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 11s 5s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 49s 24s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 45s 22s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 11s 6s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 44s 22s/step - loss: 6.8919e-07 - acc: 1.0000 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 10s 5s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 42s 21s/step - loss: 7.1992e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 14s 7s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 44s 22s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.6937 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.5229e-04 - acc: 1.0000 - val_loss: 10.6937 - val_acc: 0.3276\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 0.0218 - acc: 0.9844 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 33s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 11.0424 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 11.0424 - val_acc: 0.3276\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.5775 - acc: 0.3276\n",
      "2/2 [==============================] - 66s 33s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.5775 - val_acc: 0.3276\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.6356 - acc: 0.3276\n",
      "2/2 [==============================] - 70s 35s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.6356 - val_acc: 0.3276\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 18s 9s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 3.8254e-06 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 0.0083 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 18s 9s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.6356 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 5.3645e-07 - acc: 1.0000 - val_loss: 10.6356 - val_acc: 0.3276\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 18s 9s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 2.0862e-07 - acc: 1.0000 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.4045e-06 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 11.1587 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 11.1587 - val_acc: 0.3276\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.6937 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.6937 - val_acc: 0.3276\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 5.0106e-07 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.6937 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.6937 - val_acc: 0.3276\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.0878e-06 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.6937 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.6937 - val_acc: 0.3276\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 18s 9s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 18s 9s/step - loss: 10.6937 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.6937 - val_acc: 0.3276\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 18s 9s/step - loss: 10.9262 - acc: 0.3276\n",
      "2/2 [==============================] - 69s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.9262 - val_acc: 0.3276\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 18s 9s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 71s 36s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 18s 9s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 69s 35s/step - loss: 8.6968e-05 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8681 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8681 - val_acc: 0.3276\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 18s 9s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 18s 9s/step - loss: 10.7519 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.7519 - val_acc: 0.3276\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 18s 9s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 71s 35s/step - loss: 5.0616e-06 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 18s 9s/step - loss: 10.6937 - acc: 0.3276\n",
      "2/2 [==============================] - 68s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.6937 - val_acc: 0.3276\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 17s 9s/step - loss: 10.8100 - acc: 0.3276\n",
      "2/2 [==============================] - 67s 34s/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 10.8100 - val_acc: 0.3276\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "# Run the cell. It will take some time to execute\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=100,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [4.277229070663452,\n",
       "  6.004865884780884,\n",
       "  4.627993106842041,\n",
       "  5.302313804626465,\n",
       "  4.997298002243042,\n",
       "  4.231896281242371,\n",
       "  4.544396638870239,\n",
       "  4.820911407470703,\n",
       "  4.609843492507935,\n",
       "  4.783109664916992,\n",
       "  4.040639400482178,\n",
       "  4.281371831893921,\n",
       "  4.110368371009827,\n",
       "  4.4938740730285645,\n",
       "  3.7776790857315063,\n",
       "  4.173400163650513,\n",
       "  4.029523849487305,\n",
       "  3.724307060241699,\n",
       "  3.777678608894348,\n",
       "  3.2956778705120087,\n",
       "  1.5576672554016113,\n",
       "  0.27581050153821707,\n",
       "  1.267357736825943,\n",
       "  0.7762688398361206,\n",
       "  0.4798414185643196,\n",
       "  0.9008205980062485,\n",
       "  0.39709044992923737,\n",
       "  0.2520096004009247,\n",
       "  1.1920928955078125e-07,\n",
       "  0.2518485486507416,\n",
       "  0.13216696679592133,\n",
       "  0.003784372704103589,\n",
       "  0.32128705084323883,\n",
       "  1.2386590242385864e-07,\n",
       "  0.08745261281728745,\n",
       "  1.1920928955078125e-07,\n",
       "  1.2414732282195473e-06,\n",
       "  1.1920928955078125e-07,\n",
       "  0.007617614232003689,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  6.891891644045245e-07,\n",
       "  7.199239462352125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  0.0001522852253401652,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  0.021842099726200104,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  3.825381782007753e-06,\n",
       "  1.1920928955078125e-07,\n",
       "  0.008268383331596851,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  5.364474304769828e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  2.0861652672010678e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.4044874205865199e-06,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  5.010562631468929e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.0878148941628751e-06,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  8.696754230186343e-05,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07,\n",
       "  5.061589035904035e-06,\n",
       "  1.1920928955078125e-07,\n",
       "  1.1920928955078125e-07],\n",
       " 'acc': [0.421875,\n",
       "  0.578125,\n",
       "  0.6875,\n",
       "  0.65625,\n",
       "  0.65625,\n",
       "  0.734375,\n",
       "  0.703125,\n",
       "  0.6875,\n",
       "  0.703125,\n",
       "  0.6875,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.734375,\n",
       "  0.71875,\n",
       "  0.765625,\n",
       "  0.71875,\n",
       "  0.75,\n",
       "  0.765625,\n",
       "  0.765625,\n",
       "  0.75,\n",
       "  0.890625,\n",
       "  0.96875,\n",
       "  0.875,\n",
       "  0.921875,\n",
       "  0.921875,\n",
       "  0.921875,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'val_loss': [9.411383152008057,\n",
       "  10.841652870178223,\n",
       "  11.158681392669678,\n",
       "  10.868091106414795,\n",
       "  10.751854419708252,\n",
       "  10.809972763061523,\n",
       "  10.809972763061523,\n",
       "  10.809972763061523,\n",
       "  10.809972763061523,\n",
       "  10.926209449768066,\n",
       "  10.868091106414795,\n",
       "  11.100563049316406,\n",
       "  10.809972763061523,\n",
       "  10.809972763061523,\n",
       "  10.98432731628418,\n",
       "  10.868090629577637,\n",
       "  10.751854419708252,\n",
       "  10.984327793121338,\n",
       "  10.868090629577637,\n",
       "  10.635618686676025,\n",
       "  10.926209449768066,\n",
       "  10.984327793121338,\n",
       "  10.926209449768066,\n",
       "  10.984327793121338,\n",
       "  10.809972763061523,\n",
       "  10.868090629577637,\n",
       "  10.751854419708252,\n",
       "  10.635618209838867,\n",
       "  10.809972763061523,\n",
       "  11.042445182800293,\n",
       "  10.751854419708252,\n",
       "  10.809972763061523,\n",
       "  10.926209449768066,\n",
       "  10.926209449768066,\n",
       "  10.926209449768066,\n",
       "  10.868090152740479,\n",
       "  10.809973239898682,\n",
       "  10.868091106414795,\n",
       "  10.809972763061523,\n",
       "  10.751854419708252,\n",
       "  10.868090629577637,\n",
       "  10.868090629577637,\n",
       "  10.751854419708252,\n",
       "  10.868091106414795,\n",
       "  10.926209449768066,\n",
       "  10.751854419708252,\n",
       "  10.69373607635498,\n",
       "  10.751854419708252,\n",
       "  10.926209449768066,\n",
       "  10.868091106414795,\n",
       "  10.751854419708252,\n",
       "  10.809972763061523,\n",
       "  11.04244613647461,\n",
       "  10.926209449768066,\n",
       "  10.809972763061523,\n",
       "  10.577499866485596,\n",
       "  10.868090629577637,\n",
       "  10.635618686676025,\n",
       "  10.926209449768066,\n",
       "  10.926209449768066,\n",
       "  10.751854419708252,\n",
       "  10.868091106414795,\n",
       "  10.868090629577637,\n",
       "  10.926209449768066,\n",
       "  10.751854419708252,\n",
       "  10.809973239898682,\n",
       "  10.926209449768066,\n",
       "  10.926209449768066,\n",
       "  10.635618209838867,\n",
       "  10.926208972930908,\n",
       "  10.868090629577637,\n",
       "  10.809973239898682,\n",
       "  10.751854419708252,\n",
       "  10.809972763061523,\n",
       "  10.809972763061523,\n",
       "  11.158681392669678,\n",
       "  10.751854419708252,\n",
       "  10.69373607635498,\n",
       "  10.809972763061523,\n",
       "  10.69373607635498,\n",
       "  10.751854419708252,\n",
       "  10.868090629577637,\n",
       "  10.868090629577637,\n",
       "  10.693736553192139,\n",
       "  10.926209449768066,\n",
       "  10.926209449768066,\n",
       "  10.69373607635498,\n",
       "  10.926209449768066,\n",
       "  10.868090629577637,\n",
       "  10.809972763061523,\n",
       "  10.868091106414795,\n",
       "  10.868090629577637,\n",
       "  10.751854419708252,\n",
       "  10.868091106414795,\n",
       "  10.868090629577637,\n",
       "  10.751854419708252,\n",
       "  10.751854419708252,\n",
       "  10.809973239898682,\n",
       "  10.69373607635498,\n",
       "  10.809972763061523],\n",
       " 'val_acc': [0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862,\n",
       "  0.3275862]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-bb6bf5bcc936>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# plot the accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a h5 file\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('model_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.70157643e-15, 2.45565496e-19, 1.00000000e+00],\n",
       "       [1.07538795e-15, 1.30535884e-18, 1.00000000e+00],\n",
       "       [6.65902257e-16, 2.60345378e-18, 1.00000000e+00],\n",
       "       [1.61290807e-15, 4.26097923e-19, 1.00000000e+00],\n",
       "       [1.72563841e-15, 3.78160903e-17, 1.00000000e+00],\n",
       "       [1.67165309e-15, 4.13563707e-19, 1.00000000e+00],\n",
       "       [9.39104899e-16, 1.65997003e-19, 1.00000000e+00],\n",
       "       [1.23970599e-15, 9.08593693e-19, 1.00000000e+00],\n",
       "       [2.53070342e-15, 3.92226971e-19, 1.00000000e+00],\n",
       "       [4.82718783e-16, 1.44321963e-19, 1.00000000e+00],\n",
       "       [2.26234623e-15, 2.56200480e-19, 1.00000000e+00],\n",
       "       [5.44753782e-15, 3.80409114e-18, 1.00000000e+00],\n",
       "       [1.04670847e-15, 1.08225009e-19, 1.00000000e+00],\n",
       "       [1.99864708e-15, 7.57417079e-19, 1.00000000e+00],\n",
       "       [5.92573080e-16, 3.10532830e-19, 1.00000000e+00],\n",
       "       [1.11792795e-15, 1.16654555e-19, 1.00000000e+00],\n",
       "       [5.79863043e-15, 9.74711790e-19, 1.00000000e+00],\n",
       "       [9.81024877e-16, 2.68360629e-19, 1.00000000e+00],\n",
       "       [3.08340279e-15, 5.16092098e-19, 1.00000000e+00],\n",
       "       [9.77755860e-16, 1.37378221e-19, 1.00000000e+00],\n",
       "       [2.00780965e-15, 9.73957298e-19, 1.00000000e+00],\n",
       "       [3.62146978e-16, 2.94397418e-17, 1.00000000e+00],\n",
       "       [1.19615865e-15, 5.17949997e-19, 1.00000000e+00],\n",
       "       [2.56521768e-15, 4.76455826e-19, 1.00000000e+00],\n",
       "       [1.33222941e-15, 7.60244834e-20, 1.00000000e+00],\n",
       "       [6.65023884e-16, 5.05500257e-19, 1.00000000e+00],\n",
       "       [2.59413920e-15, 8.96847315e-20, 1.00000000e+00],\n",
       "       [8.26354808e-16, 1.46448825e-19, 1.00000000e+00],\n",
       "       [6.06243821e-16, 1.93468472e-19, 1.00000000e+00],\n",
       "       [6.39579290e-15, 5.23725683e-19, 1.00000000e+00],\n",
       "       [1.02720363e-15, 1.27731100e-18, 1.00000000e+00],\n",
       "       [4.19740639e-16, 2.51268105e-19, 1.00000000e+00],\n",
       "       [1.36736995e-15, 6.51481350e-19, 1.00000000e+00],\n",
       "       [3.52587290e-15, 6.26889270e-19, 1.00000000e+00],\n",
       "       [5.77192687e-15, 4.56965486e-19, 1.00000000e+00],\n",
       "       [2.76757385e-15, 4.92000359e-19, 1.00000000e+00],\n",
       "       [7.30784790e-15, 1.33116056e-18, 1.00000000e+00],\n",
       "       [9.60975502e-16, 6.03400443e-19, 1.00000000e+00],\n",
       "       [7.48825406e-16, 1.41945770e-19, 1.00000000e+00],\n",
       "       [4.60822854e-15, 8.49905849e-19, 1.00000000e+00],\n",
       "       [7.06559944e-16, 2.81323222e-19, 1.00000000e+00],\n",
       "       [1.07944449e-15, 1.19780457e-19, 1.00000000e+00],\n",
       "       [3.04753666e-16, 1.45026165e-19, 1.00000000e+00],\n",
       "       [1.08679483e-15, 1.11926605e-18, 1.00000000e+00],\n",
       "       [6.18035843e-16, 6.91817830e-19, 1.00000000e+00],\n",
       "       [4.26562277e-15, 5.30313711e-19, 1.00000000e+00],\n",
       "       [1.11571254e-15, 7.91543475e-20, 1.00000000e+00],\n",
       "       [4.86050544e-15, 2.24104094e-18, 1.00000000e+00],\n",
       "       [1.38611870e-15, 1.88986058e-19, 1.00000000e+00],\n",
       "       [2.42747657e-15, 4.90175702e-19, 1.00000000e+00],\n",
       "       [3.46984400e-16, 2.36104106e-18, 1.00000000e+00],\n",
       "       [1.29178115e-14, 4.52873475e-19, 1.00000000e+00],\n",
       "       [5.43705367e-15, 2.34629703e-19, 1.00000000e+00],\n",
       "       [6.50610665e-16, 1.80185296e-19, 1.00000000e+00],\n",
       "       [6.02233173e-16, 1.83951630e-19, 1.00000000e+00],\n",
       "       [3.10820116e-16, 6.99967420e-19, 1.00000000e+00],\n",
       "       [1.01345977e-16, 1.74148713e-18, 1.00000000e+00],\n",
       "       [4.58646445e-15, 1.20158076e-18, 1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('model_resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.training.Model at 0x1ff8090c488>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img('Datasets/Test/lamborghini/11.jpg',target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.keras.preprocessing.image' from 'C:\\\\Users\\\\rinki\\\\anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v1\\\\keras\\\\preprocessing\\\\image\\\\__init__.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [196., 187., 172.],\n",
       "        [217., 208., 193.],\n",
       "        [243., 234., 219.]],\n",
       "\n",
       "       [[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [245., 245., 237.],\n",
       "        [243., 243., 235.],\n",
       "        [242., 242., 234.]],\n",
       "\n",
       "       [[252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        [252., 252., 252.],\n",
       "        ...,\n",
       "        [240., 249., 248.],\n",
       "        [242., 251., 250.],\n",
       "        [242., 251., 250.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[189., 207., 229.],\n",
       "        [190., 206., 229.],\n",
       "        [190., 206., 229.],\n",
       "        ...,\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]],\n",
       "\n",
       "       [[185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        ...,\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]],\n",
       "\n",
       "       [[185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        [185., 206., 227.],\n",
       "        ...,\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.],\n",
       "        [171., 180., 187.]]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.5447111 , -0.51404   , -0.45697334],\n",
       "         [-0.5447111 , -0.51404   , -0.45697334],\n",
       "         [-0.5447111 , -0.51404   , -0.45697334],\n",
       "         ...,\n",
       "         [-0.5458173 , -0.51532394, -0.4585536 ],\n",
       "         [-0.54540247, -0.51490915, -0.45813876],\n",
       "         [-0.54488885, -0.51439553, -0.45762518]],\n",
       "\n",
       "        [[-0.5447111 , -0.51404   , -0.45697334],\n",
       "         [-0.5447111 , -0.51404   , -0.45697334],\n",
       "         [-0.5447111 , -0.51404   , -0.45697334],\n",
       "         ...,\n",
       "         [-0.5448494 , -0.5141783 , -0.45726964],\n",
       "         [-0.54488885, -0.5142178 , -0.45730916],\n",
       "         [-0.54490864, -0.5142375 , -0.4573289 ]],\n",
       "\n",
       "        [[-0.5447111 , -0.51404   , -0.45697334],\n",
       "         [-0.5447111 , -0.51404   , -0.45697334],\n",
       "         [-0.5447111 , -0.51404   , -0.45697334],\n",
       "         ...,\n",
       "         [-0.54494816, -0.51409924, -0.45705238],\n",
       "         [-0.54490864, -0.5140598 , -0.45701283],\n",
       "         [-0.54490864, -0.5140598 , -0.45701283]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.5459556 , -0.5149289 , -0.45742768],\n",
       "         [-0.5459358 , -0.5149486 , -0.45742768],\n",
       "         [-0.5459358 , -0.5149486 , -0.45742768],\n",
       "         ...,\n",
       "         [-0.5463111 , -0.5154622 , -0.45825732],\n",
       "         [-0.5463111 , -0.5154622 , -0.45825732],\n",
       "         [-0.5463111 , -0.5154622 , -0.45825732]],\n",
       "\n",
       "        [[-0.5460346 , -0.5149486 , -0.45746717],\n",
       "         [-0.5460346 , -0.5149486 , -0.45746717],\n",
       "         [-0.5460346 , -0.5149486 , -0.45746717],\n",
       "         ...,\n",
       "         [-0.5463111 , -0.5154622 , -0.45825732],\n",
       "         [-0.5463111 , -0.5154622 , -0.45825732],\n",
       "         [-0.5463111 , -0.5154622 , -0.45825732]],\n",
       "\n",
       "        [[-0.5460346 , -0.5149486 , -0.45746717],\n",
       "         [-0.5460346 , -0.5149486 , -0.45746717],\n",
       "         [-0.5460346 , -0.5149486 , -0.45746717],\n",
       "         ...,\n",
       "         [-0.5463111 , -0.5154622 , -0.45825732],\n",
       "         [-0.5463111 , -0.5154622 , -0.45825732],\n",
       "         [-0.5463111 , -0.5154622 , -0.45825732]]]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x/225\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.expand_dims(x,axis=0)\n",
    "img_data=preprocess_input(x)\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.0615530e-08, 1.8894683e-11, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.argmax(model.predict(img_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
